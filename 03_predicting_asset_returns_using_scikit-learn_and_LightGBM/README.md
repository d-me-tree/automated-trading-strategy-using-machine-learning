# Predicting Asset Returns using Linear Models and Gradient Boosting

## Objective

Build and tune different machine learning models to select those performing best on the cross-validation set to generate predictions for the out-of-sample period. 

## Workflow

For this milestone, we will experiment with two different classes of models: linear regression, including the regularized Lasso and Ridge versions, and gradient boosting. Linear models make the strong and restrictive assumption that the relationship between the features and the outcome is linear, but can be more robust when the noise-to-signal ratio is high as is typically the case for financial data. Gradient boosting, on the other hand, can learn more complex relationships and often performs better, but requires careful tuning to avoid overfitting. 

To accomplish our goal of selecting the best model(s) to generate out-of-sample predictions, we need to optimize the models' hyperparameters using a time period prior to the period during which we'll backtest our strategy. We'll be taking the following steps after reloading the dataset we created for the last milestone:
1. **Cross-validation in the time-series context** poses the additional challenge that train and validation sets need to respect the temporal order of the data so that we do not inadvertently train the model on data 'from the future' to predict the past and introduce lookahead bias. Scikit-learn's built-in [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) aims to accomplish this but does not work for this case where we have multiple time series, one for each ticker. We could solve this by manually subsetting the data for the appropriate train and validation periods. Alternatively, we can create a custom time-series splitter compatible with the scikit-learn Kfold interface (see resources). Here is an [example](https://github.com/stefan-jansen/machine-learning-for-trading/blob/master/utils.py) that illustrates how to do so for this case. This allows us to specify fixed `train_length` and `test_length` parameters, as well as a `lookahead` value that defines the forecast horizon and ensures an appropriate gap between the training and validation set.
2. To establish a **baseline**, train a [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) using five years of training data to predict rolling windows of three months of returns for the years 2013-2016. Evaluate the results by computing the information coefficient (IC) as the Spearman rank correlation between the predictions and the actual returns, averaged per day.
3. Next, we'll use **regularized regression** models that include a penalty term to shrink the coefficients and limit the risk of overfitting. Cross-validate a range of `alpha` penalty values for [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) and [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) using the same training and validation periods as for the linear regression baseline and compare their performance.
4. Now, we'll investigate if a more complex **gradient boosting** model is capable of improving the result. 
    - We'll use the LightGBM implementation because it often [outperforms](https://lightgbm.readthedocs.io/en/latest/Experiments.html) the alternative [XGBoost](https://xgboost.readthedocs.io/en/latest/) and [CatBoost](https://catboost.ai/) libraries, especially in terms of runtime and memory footprint. There is also a recent scikit-learn [HistGradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html#sklearn.ensemble.HistGradientBoostingRegressor) inspired by LightGBM. 
    - You need to define and [tune](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html) several **hyperparameters** to define the model's complexity as well as constraints on the learning process (see [docs](https://lightgbm.readthedocs.io/en/latest/Parameters.html) for the full list). The goal is to adjust the model's capacity to the data while limiting the risk of overfitting so that the model learns the signal rather than the noise in the data and generalizes better to out-of-sample data. In other words, we aim to identify the most promising model settings based on an unbiased estimate of the generalization error, and then apply these settings to generate out-of-sample predictions.
    - The **most important parameters** define the *number of iterations* or trees, and the *size of each tree*. LightGBM allows you to optimize the number of iterations by training a model for a certain number of iterations, then evaluating its performance before continuing to train the model. LightGBM permits [leaf-wise tree growth](https://lightgbm.readthedocs.io/en/latest/Features.html#leaf-wise-best-first-tree-growth) and let's you limit the size of the tree by setting the number of leaf nodes or by limiting the depth of the tree. A useful combination targets a certain number of leaves while constraining the minimum number of samples per leaf node to avoid excessive tree imbalances as well as noisy estimates due to leaf nodes with few samples. The default value of 32 of the number of leaves is a good starting point, but the min. number of data points per leaves should be significantly higher than the default of 20 - with 1m observations and 100 leave nodes, each leaf would on average contain 10K samples. 
    - A lower learning rate can help boost accuracy but requires more iterations and, thus, extends training time. See also LightGBM's [guidance](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html) on parameter tuning.
    - Finally, the parameter `feature_frac` let's you control the amount of randomization while building each tree.
5. To **evaluate the model performance**, compare the cross-validation IC for different hyperparameter settings, computed again as the average of the Spearman rank correlation of the model predictions for each day with the actual returns. Identify the best-performing 5-10 models over a number of recent quarters, and check whether averaging their predictions further improves the result. In addition, use Alphalens to compute a summary tearsheet and inspect the spread between the botton and the top quintile of the predictions.
6. Generate out-of-sample predictions for 2014-2016 using your preferred models (which may change for every quarter), and possibly average the result if you found this to yield more stable results. Repeat your Alphalens analysis for these signals.

## Importance to project

The predictions generated by the machine learning models you build for this milestone will inform the trading strategy you will design for the next and final milestone.  

## Resources

- Scikit-learn user guide on [cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)
- [Extending the Fundamental Law of Investment Management](https://www.semanticscholar.org/paper/Extending-the-Fundamental-Law-of-Investment-Trichilo-Braun/10fb18e8f8a0b57a51aba74c9dde66523d7389ae)
- [Tree-based Methods](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapter 8 in An Introduction to Statistical Learning, Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani
- [Boosting and Additive Trees](https://web.stanford.edu/~hastie/Papers/ESLII.pdf), Chapter 10 in Elements of Statistical Learning by Trevor Hastie, Robert Tibshirani, and Jerome Friedman
- LightGBM [documentation](https://lightgbm.readthedocs.io/en/latest/)
- Alphalens [documentation](http://quantopian.github.io/alphalens/)